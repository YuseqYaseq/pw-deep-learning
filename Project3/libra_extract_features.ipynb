{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Masking\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical, Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_set(filename, validation_percentage, testing_percentage):\n",
    "    \"\"\"Determines which data partition the file should belong to.\n",
    "\n",
    "    We want to keep files in the same training, validation, or testing sets even\n",
    "    if new ones are added over time. This makes it less likely that testing\n",
    "    samples will accidentally be reused in training when long runs are restarted\n",
    "    for example. To keep this stability, a hash of the filename is taken and used\n",
    "    to determine which set it should belong to. This determination only depends on\n",
    "    the name and the set proportions, so it won't change as other files are added.\n",
    "\n",
    "    It's also useful to associate particular files as related (for example words\n",
    "    spoken by the same person), so anything after '_nohash_' in a filename is\n",
    "    ignored for set determination. This ensures that 'bobby_nohash_0.wav' and\n",
    "    'bobby_nohash_1.wav' are always in the same set, for example.\n",
    "\n",
    "    Args:\n",
    "    filename: File path of the data sample.\n",
    "    validation_percentage: How much of the data set to use for validation.\n",
    "    testing_percentage: How much of the data set to use for testing.\n",
    "\n",
    "    Returns:\n",
    "    String, one of 'train', 'validation', or 'test'.\n",
    "    \"\"\"\n",
    "    validation_percentage *= 100\n",
    "    testing_percentage *= 100\n",
    "    MAX_NUM_WAVS_PER_CLASS = 2**27 - 1  # ~134M\n",
    "    base_name = os.path.basename(filename)\n",
    "    # We want to ignore anything after '_nohash_' in the file name when\n",
    "    # deciding which set to put a wav in, so the data set creator has a way of\n",
    "    # grouping wavs that are close variations of each other.\n",
    "    hash_name = re.sub(r'_nohash_.*$', '', base_name)\n",
    "    # This looks a bit magical, but we need to decide whether this file should\n",
    "    # go into the training, testing, or validation sets, and we want to keep\n",
    "    # existing files in the same set even if more files are subsequently\n",
    "    # added.\n",
    "    # To do that, we need a stable way of deciding based on just the file name\n",
    "    # itself, so we do a hash of that and then use that to generate a\n",
    "    # probability value that we use to assign it.\n",
    "    hash_name_hashed = hashlib.sha1(hash_name.encode('utf-8')).hexdigest()\n",
    "    percentage_hash = ((int(hash_name_hashed, 16) %\n",
    "                      (MAX_NUM_WAVS_PER_CLASS + 1)) *\n",
    "                     (100.0 / MAX_NUM_WAVS_PER_CLASS))\n",
    "    \n",
    "    if percentage_hash < validation_percentage:\n",
    "        result = 'validation'\n",
    "    elif percentage_hash < (testing_percentage + validation_percentage):\n",
    "        result = 'test'\n",
    "    else:\n",
    "        result = 'train'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for extracting features from the entire dataset\n",
    "def shuffle_in_unison(x, y, seed=None):\n",
    "    assert len(x) == len(y)\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    p = np.random.permutation(len(x))\n",
    "    return x[p], y[p]\n",
    "\n",
    "def get_data(path: str, dataset: str, labels: list,\n",
    "                 validation_size: float, test_size: float,\n",
    "                 n_mfcc: int=13, hop_length: int=512, timeseries_length: int=64):\n",
    "    if dataset not in ['train', 'test', 'validation']:\n",
    "        raise RuntimeError(\"Select one of \\'train\\', \\'test\\', \\'validation\\'\")\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    if 'unknown' not in labels:\n",
    "        labels.append('unknown')\n",
    "    no_labels = len(labels)\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if len(files) > 0:\n",
    "            label = root.split('\\\\')[-1]\n",
    "            x += [Path(root) / file for file in files\n",
    "                       if which_set(file, validation_size, test_size) == dataset]\n",
    "            no = labels.index(label) if label in labels else labels.index('unknown')\n",
    "            y += [no for file in files\n",
    "                       if which_set(file, validation_size, test_size) == dataset]\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    y = to_categorical(y)\n",
    "    x, y = shuffle_in_unison(x, y, seed=1)\n",
    "\n",
    "    #####\n",
    "    # lets try to load all the data\n",
    "    data = np.zeros((len(x), timeseries_length, n_mfcc+20))\n",
    "    max_mfcc_length = 0\n",
    "\n",
    "    print(\"Loading audio files...\")\n",
    "    for i, file in enumerate(x):\n",
    "        print(f\"\\r{i}/{len(x)}\", end='')\n",
    "        file_path = x[i]\n",
    "        audio, sr = librosa.load(file_path)\n",
    "        mfcc = librosa.feature.mfcc(\n",
    "            y=audio, sr=sr, hop_length=hop_length, n_mfcc=n_mfcc\n",
    "        )\n",
    "        spectral_center = librosa.feature.spectral_centroid(\n",
    "            y=audio, sr=sr, hop_length=hop_length\n",
    "        )\n",
    "        chroma = librosa.feature.chroma_stft(y=audio, sr=sr, hop_length=hop_length)\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(\n",
    "            y=audio, sr=sr, hop_length=hop_length\n",
    "        )\n",
    "        if len(mfcc) > max_mfcc_length:\n",
    "            max_mfcc_length = len(mfcc)\n",
    "        mfcc = mfcc.T[0:timeseries_length, :]\n",
    "        data[i, 0:len(mfcc), 0:n_mfcc] = mfcc\n",
    "        data[i, 0:len(mfcc), n_mfcc:n_mfcc+1] = spectral_center.T[0:timeseries_length, :]\n",
    "        data[i, 0:len(mfcc), n_mfcc+1:n_mfcc+13] = chroma.T[0:timeseries_length, :]\n",
    "        data[i, 0:len(mfcc), n_mfcc+13:n_mfcc+20] = spectral_contrast.T[0:timeseries_length, :]\n",
    "    \n",
    "    #data = data[:, 0:max_mfcc_length, :]\n",
    "    print(f\"\\r{len(x)}/{len(x)}\")\n",
    "    return data, y, max_mfcc_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio files...\n",
      "6798/6798\n"
     ]
    }
   ],
   "source": [
    "# Extract features from audio files\n",
    "validation_size = 0.1\n",
    "test_size = 0.1\n",
    "labels=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown']\n",
    "\n",
    "train_x, train_y, train_max_mfcc_length = get_data(Path('train/audio'), 'train',\n",
    "                            labels, validation_size, test_size)\n",
    "validation_x, validation_y, val_max_mfcc_length = get_data(Path('train/audio'), 'validation',\n",
    "                                      labels, validation_size, test_size)\n",
    "test_x, test_y, test_max_mfcc_length = get_data(Path('train/audio'), 'test',\n",
    "                          labels, validation_size, test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These np arrays need a lot of time to create so we'll save them in case something goes wrong.\n",
    "np.save(Path('train/train_x_13mfcc'), train_x)\n",
    "np.save(Path('train/train_y_13mfcc'), train_y)\n",
    "np.save(Path('train/validation_x_13mfcc'), validation_x)\n",
    "np.save(Path('train/validation_y_13mfcc'), validation_y)\n",
    "np.save(Path('train/test_x_13mfcc'), test_x)\n",
    "np.save(Path('train/test_y_13mfcc'), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case something goes wrong restore the data\n",
    "train_x = np.load(Path('train/train_x_13mfcc'))\n",
    "train_y = np.load(Path('train/train_y_13mfcc'))\n",
    "validation_x = np.load(Path('train/validation_x_13mfcc'))\n",
    "validation_y = np.load(Path('train/validation_y_13mfcc'))\n",
    "test_x = np.load(Path('train/test_x_13mfcc'))\n",
    "test_y = np.load(Path('train/test_y_13mfcc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0., input_shape=(None, 33)))\n",
    "    model.add(LSTM(8))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(len(labels), activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32550  1861  1885  1839  1864  1852  1839  1842  1843  1853  1860]\n",
      "{0: 32550, 1: 1861, 2: 1885, 3: 1839, 4: 1864, 5: 1852, 6: 1839, 7: 1842, 8: 1843, 9: 1853, 10: 1860}\n"
     ]
    }
   ],
   "source": [
    "# 'unknown' class is extremely unbalanced\n",
    "_, counts = np.unique(train_y, return_counts=True, axis=0)\n",
    "class_weight = dict(zip(range(11), counts))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_3 (Masking)          (None, None, 33)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 8)                 1344      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               1152      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 11)                1419      \n",
      "=================================================================\n",
      "Total params: 3,915\n",
      "Trainable params: 3,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "51088/51088 [==============================] - 98s 2ms/step - loss: 4591.4825 - accuracy: 0.3348\n",
      "Epoch 2/3\n",
      "51088/51088 [==============================] - 89s 2ms/step - loss: 4136.6739 - accuracy: 0.4453\n",
      "Epoch 3/3\n",
      "51088/51088 [==============================] - 86s 2ms/step - loss: 3994.9004 - accuracy: 0.5569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x29ceccc3448>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.fit(train_x, train_y, batch_size=64, epochs=3, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
